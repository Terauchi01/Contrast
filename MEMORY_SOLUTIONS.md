## N-tuple メモリ使用量の問題と解決策

### 現状の問題
- 10種類の基本パターン × 平行移動 = 18パターン
- 各パターン: 9^9 = 387,420,489 状態 ≈ 1.44 GB
- **合計: 約26GB** ← 実用不可能

### 解決策の選択肢

#### 1. パターンを厳選する（推奨）
最も重要なパターンだけを使用：
```
- 3x3 square (1種類 × 3移動 = 3パターン)
- Cross-2 (1種類 × 6移動 = 6パターン)  ← 3x3で移動可能
合計: 9パターン ≈ 13GB
```

#### 2. より小さいパターンを使う
9セル → 6セルに削減：
```
- 各パターン: 9^6 = 531,441 状態 ≈ 2MB
- 18パターン × 2MB = 36MB ← 非常に軽量！
- ただし表現力が低下
```

#### 3. パターンの重複を減らす
回転バージョンを削除し、対称性は評価時に処理：
```
- 基本形のみ（回転なし）
- evaluate()で8方向の対称性をチェック
- メモリ削減、計算コストは少し増加
```

#### 4. ハッシュテーブルを使う（スパース表現）
```
- 実際に訪問した状態のみメモリ確保
- unordered_map<long long, float>
- 初期メモリ: ほぼゼロ
- 学習が進むと増加（数百MB〜数GB）
```

### 推奨アプローチ
**オプション1 + オプション2の組み合わせ**
- 6セルの小さいパターンを多数使用
- メモリ効率的で、多様な特徴を捉えられる
- 合計50パターンでも 100MB程度

どのアプローチを試しますか？
